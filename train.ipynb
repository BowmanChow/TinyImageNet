{"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"pytorch-1.4.0","display_name":"Pytorch-1.4.0","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["from torch.autograd import Variable\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","import torch.utils.data as data\n","import torchvision.models as models\n","import matplotlib.image as pli\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import numpy as np\n","from PIL import Image\n","from PIL import ImageOps\n","import random\n","import math"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_transform = transforms.Compose(\n","    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","file_path = './TinyImageNet'"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def rotatedRectWithMaxArea(w, h, angle):\n","    \"\"\"\n","    Given a rectangle of size wxh that has been rotated by 'angle' (in\n","    radians), computes the width and height of the largest possible\n","    axis-aligned rectangle (maximal area) within the rotated rectangle.\n","    \"\"\"\n","    if w <= 0 or h <= 0:\n","        return 0,0\n","\n","    width_is_longer = w >= h\n","    side_long, side_short = (w,h) if width_is_longer else (h,w)\n","\n","    # since the solutions for angle, -angle and 180-angle are all the same,\n","    # if suffices to look at the first quadrant and the absolute values of sin,cos:\n","    sin_a, cos_a = abs(math.sin(angle)), abs(math.cos(angle))\n","    if side_short <= 2.*sin_a*cos_a*side_long or abs(sin_a-cos_a) < 1e-10:\n","        # half constrained case: two crop corners touch the longer side,\n","        #   the other two corners are on the mid-line parallel to the longer line\n","        x = 0.5*side_short\n","        wr,hr = (x/sin_a,x/cos_a) if width_is_longer else (x/cos_a,x/sin_a)\n","    else:\n","        # fully constrained case: crop touches all 4 sides\n","        cos_2a = cos_a*cos_a - sin_a*sin_a\n","        wr,hr = (w*cos_a - h*sin_a)/cos_2a, (h*cos_a - w*sin_a)/cos_2a\n","\n","    return wr,hr"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_num = 100\n","\n","class ImageSet(data.Dataset):\n","    def __init__(self):\n","        self.length = 1000 * 1000\n","\n","    def __getitem__(self, index):\n","        # print(index)\n","        label = index % label_num\n","        img_count = int(index / label_num) % 1000\n","\n","        img = Image.open(f'{file_path}/train/{label}/{label}_{0 + img_count}.jpg')\n","        rand = random.randint(0, 11)\n","        \n","        img = img.rotate(rand, expand=False)\n","        new_width, new_height = rotatedRectWithMaxArea(64,64,rand / 180 * math.pi)\n","        new_width = max(new_width, 56)\n","        new_height = max(new_height, 56)\n","        \n","        crop_area = ((img.size[0]-new_width)/2, (img.size[1]-new_height)/2, (img.size[0]+new_width)/2, (img.size[1]+new_height)/2)\n","        \n","        img = img.crop(crop_area)\n","        \n","        rand = random.randint(0, 1)\n","        \n","        if rand == 0:\n","            img = ImageOps.mirror(img)\n","            \n","        randx = random.randint(0, img.size[0] - 56)\n","        randy = random.randint(0, img.size[1] - 56)\n","        \n","        img = img.crop((randx, randy, 56+randx, 56+randy))\n","        \n","        img = my_transform(img)\n","        \n","        return img, label\n","\n","    def __len__(self):\n","        return self.length"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = data.DataLoader(ImageSet(), batch_size=256, shuffle=True)\n","test_loader = data.DataLoader(ImageSet(), batch_size=1, shuffle=True)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["convNet = models.resnet18()\n","convNet.conv1 = nn.Sequential(\n","    nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n","    nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))\n","convNet.maxpool = nn.Sequential()\n","# convNet.layer4 = nn.Sequential()\n","convNet.fc = nn.Linear(512,label_num)\n","print(convNet)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 加载模型， 请谨慎操作， 会覆盖在内存中的模型\n","convNet = models.resnet18()\n","convNet.conv1 = nn.Sequential(\n","    nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n","    nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))\n","convNet.maxpool = nn.Sequential()\n","# convNet.layer4 = nn.Sequential()\n","convNet.fc = nn.Linear(512,label_num)\n","convNet.load_state_dict(torch.load('./ConvNet.model'))\n","convNet.eval()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(convNet.parameters(), lr=0.003)\n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["convNet.train()\n","device = torch.device(\"cuda\")\n","convNet = convNet.to(device)\n","for i, (images, labels) in enumerate(train_loader):\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs = convNet(images)\n","    loss = loss_func(outputs, labels)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    predict = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n","    if i % 10 == 0:\n","        print(f\"i = {i},  loss = {loss},  accuracy = {float(sum(labels == predict))/float(labels.size(0))}\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 保存模型， 请谨慎操作， 会覆盖文件中的模型\n","torch.save(convNet.state_dict(), './ConvNet.model')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import moxing as mox\n","mox.file.copy_parallel(\"ConvNet.model\",\"obs://deep-learning-hw2-zzzzzzjjjbbb/ConvNet.model\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}